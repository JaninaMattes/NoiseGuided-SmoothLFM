# ðŸš€ NoiseGuided-SmoothLFM

**NoiseGuided-SmoothLFM** is a framework for learning **noise-guided latent smoothness** in image generation.  
It builds on top of **Image Latent Diffusion Model** ([image-ldm](https://github.com/joh-schb/image-ldm)) and leverages the power of 


**Scalable Interpolant Transformers (SiT)** ([SiT](https://github.com/willisma/SiT)).

---

## ðŸ’¡ Highlights

- âœ… Uses **pre-trained SiT (Scalable Interpolant Transformers)** as the backbone, which are built on Diffusion Transformers (DiT).
- ðŸ§Š Employs **smoothness constraints** in the latent space for better editing, interpolation, and stability.
- ðŸ”¬ Includes advanced quantitative evaluations: PCA projections, linear probes, UMAP visualizations, and smoothness metrics (ISTD, LDPL).
- ðŸ“ˆ Integrated support for FID, Inception Score, LPIPS, SSIM, PSNR, and custom smoothness metrics.
- ðŸ’¥ Supports advanced ODE-based sampling via `torchdiffeq`.

---

## ðŸ“¦ Repository Contents

- `train.py` â€” Main training entry point for SiT-based models, including smoothness losses.
- `evaluation/` â€” Scripts for:
  - PCA and linear probe evaluations
  - UMAP projections
  - Full image metric tracking (FID, precision-recall, smoothness)
- `configs/` â€” Example training & sampling configurations.
- `environment.yml` â€” Conda environment file.

---

## ðŸ”§ Setup

Clone and enter the repository:

```bash
git clone <your-repo-url>
cd <your-repo-folder>
